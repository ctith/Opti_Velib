# Analyse des données

Fichier stations_lyon_geo.csv, 349 lignes et 10 variables 
![](https://github.com/ctith/Projet_Velib/blob/master/Diagrammes/2018-04-13%2017_46_26-sations%20lyon.png)

Fichiers data.csv, 5 variables pour 2015 à 2018, 2016 et 2017
![](https://github.com/ctith/Projet_Velib/blob/master/Diagrammes/2018-04-13%2011_43_29-all%20data.png)
![](https://github.com/ctith/Projet_Velib/blob/master/Diagrammes/2018-04-13%2018_20_46-data%202016.png)
![](https://github.com/ctith/Projet_Velib/blob/master/Diagrammes/2018-04-13%2018_21_02-data%202017.png)


# Spark ML

## Création d'un objet scala pointant vers le dataframe
```scala
ubuntu:~$ sudo su spark
spark:/home/ubuntu$ export SPARK_MAJOR_VERSION=2
spark:/home/ubuntu$ cd /usr/hdp/current/spark2-client/
spark:/usr/hdp/current/spark2-client$ ./bin/spark-shell
```

## Import des fichiers csv
```scala
scala> val stations = spark.read.format("csv").option("header", "true").option("inferSchema", "true").load("/user/hadoop/stations_lyon.csv")
scala> val data = spark.read.format("csv").option("header", "true").option("inferSchema", "true").load("/user/hadoop/data_lyon_2017.csv")
```

### Vérification du typage du dataframe
```scala
scala> :type data
org.apache.spark.sql.DataFrame
```

### Affichage du schéma inférencé du dataframe
```scala
scala> data.printSchema()

```

### Affichage des données
```scala
scala> data.show()

```



