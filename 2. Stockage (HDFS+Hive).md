# Stockage des données dans HDFS

## Envoi des données vers AWS
```shell
ctith@L50T-048:/$ sudo scp -r -i NC_AWS_KEY.pem /mnt/c/Users/Fitec/IdeaProjects/velib/sql/data_output.csv ubuntu@54.194.196.141:/home/ubuntu
[sudo] Mot de passe de ctith :
data_output.csv                                                                                             100% 4940MB   5.4MB/s   15:17

ctith@L50T-048:/$ sudo scp -r -i NC_AWS_KEY.pem /mnt/c/Users/Fitec/IdeaProjects/velib/sql/data_lyon.csv ubuntu@54.194.196.141:/home/ubuntu
[sudo] Mot de passe de ctith :
data_lyon.csv                                                                                               100%  658MB   5.5MB/s   02:00
```

## Envoie des données de AWS vers HDFS

### Connexion en tant qu'user hdfs
```shell
ubuntu@ip-172-31-30-85:~$ ls
csv   data_lyon_2015.csv  data_lyon_2017.csv  data_lyon.csv    exo           kafka_2.11-1.0.0
data  data_lyon_2016.csv  data_lyon_2018.csv  data_output.csv  jdk1.8.0_161  meteo.py

ubuntu@ip-privée-aws:~$ sudo su hdfs
```

### Envoyer les fichiers csv vers hdfs
```shell
hdfs@ip-172-31-30-85:/home/ubuntu$ hdfs dfs -put data_output.csv /user/hadoop/
```

### Vérification du bon envoi des fichiers sur hdfs
```shell
hdfs@ip-172-31-30-85:/home/ubuntu$ hdfs dfs -ls /user/hadoop
Found 6 items
-rw-r--r--   3 hdfs hdfs  689963590 2018-04-06 13:29 /user/hadoop/data_lyon.csv
-rw-r--r--   3 hdfs hdfs   17427610 2018-04-06 15:05 /user/hadoop/data_lyon_2015.csv
-rw-r--r--   3 hdfs hdfs  330184357 2018-04-06 15:05 /user/hadoop/data_lyon_2016.csv
-rw-r--r--   3 hdfs hdfs  278195237 2018-04-06 15:05 /user/hadoop/data_lyon_2017.csv
-rw-r--r--   3 hdfs hdfs   64156310 2018-04-06 15:05 /user/hadoop/data_lyon_2018.csv
-rw-r--r--   3 hdfs hdfs      43704 2018-04-13 13:00 /user/hadoop/stations_lyon.csv
```

-----------------------------
# HiveQL

## Créer une BDD Hive
Input :
```SQL
CREATE DATABASE IF NOT EXISTS velib;
```
Output:
```SQL
OK
Time taken: 1.995 seconds
```

## Autoriser l'utilisation de mots-clés de Hive
Le mot timestamp est un mot réservé par Hive mais on va permettre l'utilisation de ce mot pour notre BDD.
```SQL
SET hive.support.sql11.reserved.keywords=false;
```
## Création des tables 

Tables "contracts, stations, data" dans la BDD "velib" 

Puis importation des fichiers csv selon le délimiteur ","

### Table CONTRACT

#### Création de la table CONTRACT
Input:
```SQL
CREATE TABLE IF NOT EXISTS velib.contract ( 
        contract_id INT,
        timestamp INT,
        contract_name STRING,
        commercial_name STRING,
        country_code STRING,
        cities STRING);
```
Output:
```SQL
OK
Time taken: 0.283 seconds
```

#### Insertion des données de contract : ville de Lyon
Input:
```SQL
INSERT INTO TABLE velib.contract VALUES (14,1522022702,'Lyon','Vélo\'V','FR','Caluire-et-Cuire/Lyon/Vaulx-En-Velin/Villeurbanne');
```

Output:
```SQL
Query ID = hdfs_20180413130856_8de43574-1b22-4edc-97fc-ce365fdd47b7
Total jobs = 1
Launching Job 1 out of 1
Status: Running (Executing on YARN cluster with App id application_1523606241403_0002)

--------------------------------------------------------------------------------
        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
--------------------------------------------------------------------------------
Map 1 ..........   SUCCEEDED      1          1        0        0       0       0
--------------------------------------------------------------------------------
VERTICES: 01/01  [==========================>>] 100%  ELAPSED TIME: 3.78 s
--------------------------------------------------------------------------------
Loading data to table velib.contract
Table velib.contract stats: [numFiles=1, numRows=1, totalSize=80, rawDataSize=79]
OK
Time taken: 6.006 seconds
```
---------------
### Table STATIONS

#### Création de la table STATIONS
Input:
```SQL
CREATE TABLE IF NOT EXISTS velib.stations ( 
        contract_id INT,
        station_number STRING,
        status STRING,
        bike_stands STRING,
        bonus STRING,
        banking STRING,
        latitude FLOAT,
        longitude FLOAT,
        address STRING,
        station_name STRING);
```

Output:
```SQL
OK
Time taken: 0.176 seconds
```

#### Insertion des données de stations de Lyon
Input:
```SQL
ALTER TABLE velib.stations SET SERDEPROPERTIES ('field.delim' = '\,');
LOAD DATA INPATH '/user/hadoop/stations_lyon.csv' OVERWRITE INTO TABLE velib.stations ;
```

Output:
```SQL
OK
Time taken: 0.277 seconds
Loading data to table velib.stations
Table velib.stations stats: [numFiles=1, numRows=0, totalSize=43704, rawDataSize=0]
OK
Time taken: 0.638 seconds
```

----------------
### Table DATA

#### Création de la table DATA
Input:
```SQL
CREATE TABLE IF NOT EXISTS velib.data ( 
        timestamp INT,
        contract_id INT,
        station_number INT,
        available_bikes INT,
        available_bike_stands INT);
```
Output:
```SQL
OK
Time taken: 0.159 seconds
```

#### Insertion des données 
Input:
```SQL
ALTER TABLE velib.data SET SERDEPROPERTIES ('field.delim' = '\,');
LOAD DATA INPATH '/user/hadoop/data_lyon.csv' OVERWRITE INTO TABLE velib.data ;
```

Output:
```SQL
OK
Time taken: 0.28 seconds
Loading data to table velib.data
Table velib.data stats: [numFiles=1, numRows=0, totalSize=689963590, rawDataSize=0]
OK
Time taken: 0.738 seconds
```


